# Q&A：常见问题与回答

你可以通过阅读当前模块快速了解本章重点内容。

*   Q：什么是 GPT3、GPT4、ChatGPT？
    GPT-3 (Generative Pretrained Transformer 3) 和 GPT-4 是 OpenAI 开发的语言处理 AI 模型，

    ChatGPT 则是使用语言处理 AI 模型创建的一个有高度能力的聊天机器人

    简单地说，GPT-3 让用户能够给受过训练的 AI 提供各种文字提示。这些可以是问题、请求在所选主题上撰写文本或大量其他的文字请求。



*   Q：ChatGPT 能做什么？

    它具有相当广泛的能力，从在替代宇宙中写关于有感情的屁话和陈词滥调的浪漫喜剧，到用简单的术语解释量子力学或撰写全文研究论文和文章。

    ![https://images.immediate.co.uk/production/volatile/sites/4/2022/12/Screenshot-2022-12-07-at-11.20.53-090e0ad-e1671540029989.png?quality=90\&resize=700,157](https://images.immediate.co.uk/production/volatile/sites/4/2022/12/Screenshot-2022-12-07-at-11.20.53-090e0ad-e1671540029989.png?quality=90\&resize=700,157)

    虽然使用OpenAI多年的研究让AI编写糟糕的单口喜剧脚本，或回答关于你最喜欢的名人的问题可能很有趣，但它的力量在于其速度和对复杂问题的理解。我们可能会花费数小时研究、理解和撰写有关量子力学的文章，而ChatGPT可以在几秒钟内生成一篇写得不错的替代作品。

    它有其局限性，如果你的提示开始变得太复杂，甚至只是走了一条变得有点太小众的路线，其软件就很容易搞砸。同样，它无法处理过于新颖的概念。过去一年发生的世界事件将会面临有限的知识，该模型偶尔会产生虚假或混淆的信息。



*   Q：有什么像 GPT 一样的其它的语言处理 AI 模型吗？

    虽然 GPT-3 因其语言能力而声名鹊起，但它不是唯一能够做到这一点的人工智能。目前有一些像 GPT 这样的语言处理 AI 模型，包括：

    * BERT（Bidirectional Encoder Representations from Transformers）：Google 开发的预训练语言模型，它使用 Transformer 网络结构，可以生成高质量的文本。
    * RoBERTa（A Robustly Optimized BERT Pretraining Approach）：Facebook 开发的预训练语言模型，使用与 BERT 相同的 Transformer 网络结构，但采用了更大的数据集和训练步骤，以提高性能。
    * T5（Text-to-Text Transfer Transformer）：Google 开发的预训练语言模型，可以处理各种 NLP 任务，例如文本摘要、问答和翻译。

    这些模型中大多数并不向公众开放，但 OpenAI 已开始在其测试过程中开放访问 GPT-3，而 Google 的 LaMDA 则以有限的测试能力向选定的群体开放。



*   Q：为什么 ChatGPT 会引发这么大的轰动？

    ```jsx
    $todo$
    ```
