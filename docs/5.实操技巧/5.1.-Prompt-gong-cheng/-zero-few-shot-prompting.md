---
sidebar_position: 3
---

# 5.1.3. Zero/Few-Shot Prompting

## Zero-Shot Prompting 零样本提示

经过大量数据训练并调整指令的 LLM 能够执行零样本任务，也就是不需要给 AI 模型提供任何示例，它也可以较好地完成任务。

我们在这里是简单地阐述这个概念，读者并不需要做什么额外的操作来「使用」这个技巧。

**输入**：

```jsx
将文本分类为中性、负面或正面。
文本：我认为这次假期还可以。
情感：
```

输出：

`中性`

在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。当零样本不起作用时，建议在提示中提供示例以启用 AI 模型的上下文学习能力。

## In-Context Learning 上下文学习

预训练的大型语言模型（LLMs）是强大的语境学习者，能够在不改变模型参数的情况下进行少量的学习。

**用更直白的话语来解释就是：现在的大语言模型是可以听懂你在 Prompt 中举出的例子，并学习你举的例子来举一反三。**

在谷歌团队 [Larger language models do in-context learning differently](https://arxiv.org/abs/2303.03846) 论文的研究中发现，在评估了指令调整的模型后发现，指令调整既加强了语义先验的使用，也加强了学习输入-标签映射的能力。

即使在模型的预训练中没有相关的语料，甚至在我们 Prompt 的过程中推翻了之前训练的语料，模型也能够较好地完成我们的任务。


## Few-Shot Prompting 少样本提示

虽然大型语言模型展示了惊人的零样本能力，但在使用零样本设置时，它们在更复杂的任务上仍然表现不佳。**少样本提示可以作为一种技术，以启用上下文学习**，我们在提示中提供演示以引导模型实现更好的性能。

通过向大语言模型展示一些少量的样例，并在样例中解释推理过程，大语言模型在回答提示时也会显示推理过程。这种推理的解释往往会引导出更准确的结果。

```
$todo$
```